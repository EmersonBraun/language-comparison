"use strict";(globalThis.webpackChunklanguage_comparison_docs=globalThis.webpackChunklanguage_comparison_docs||[]).push([[185],{4831(n,e,a){a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"concurrency-async","title":"Concurrencia y Asincron\xeda","description":"Modelos de concurrencia -- async/await, hilos, goroutines y actores en 12 lenguajes","source":"@site/i18n/es/docusaurus-plugin-content-docs/current/concurrency-async.md","sourceDirName":".","slug":"/concurrency-async","permalink":"/language-comparison/es/docs/concurrency-async","draft":false,"unlisted":false,"editUrl":"https://github.com/EmersonBraun/language-comparison/tree/main/docs/concurrency-async.md","tags":[],"version":"current","sidebarPosition":24,"frontMatter":{"sidebar_position":24,"description":"Modelos de concurrencia -- async/await, hilos, goroutines y actores en 12 lenguajes","keywords":["concurrencia","async","await","hilos","goroutines","actores","paralelo"]},"sidebar":"tutorialSidebar","previous":{"title":"Null Safety & Optionals","permalink":"/language-comparison/es/docs/null-safety"},"next":{"title":"Memory Management","permalink":"/language-comparison/es/docs/memory-management"}}');var r=a(4848),o=a(8453),c=a(6153);const s={sidebar_position:24,description:"Modelos de concurrencia -- async/await, hilos, goroutines y actores en 12 lenguajes",keywords:["concurrencia","async","await","hilos","goroutines","actores","paralelo"]},i="Concurrencia y Asincron\xeda",l={},d=[{value:"Ejecuci\xf3n As\xedncrona / Concurrente B\xe1sica",id:"ejecuci\xf3n-as\xedncrona--concurrente-b\xe1sica",level:2},{value:"Seguridad de Hilos y Sincronizaci\xf3n",id:"seguridad-de-hilos-y-sincronizaci\xf3n",level:2},{value:"Puntos Clave",id:"puntos-clave",level:2}];function u(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"concurrencia-y-asincron\xeda",children:"Concurrencia y Asincron\xeda"})}),"\n",(0,r.jsx)(e.p,{children:"Los modelos de concurrencia son uno de los mayores diferenciadores entre lenguajes de programaci\xf3n. As\xed es como los diferentes lenguajes manejan la programaci\xf3n as\xedncrona, los hilos y la ejecuci\xf3n concurrente."}),"\n","\n",(0,r.jsx)(e.h2,{id:"ejecuci\xf3n-as\xedncrona--concurrente-b\xe1sica",children:"Ejecuci\xf3n As\xedncrona / Concurrente B\xe1sica"}),"\n",(0,r.jsx)(c.A,{languages:[{name:"JavaScript",lang:"javascript",code:'// Promises\nconst fetchData = () => {\n  return new Promise((resolve) => {\n      setTimeout(() => resolve("data"), 1000);\n  });\n};\n\n// Async/await\nasync function main() {\n  const result = await fetchData();\n  console.log(result);\n}\n\n// Promise.all (parallel)\nconst [a, b] = await Promise.all([\n  fetchData(),\n  fetchData(),\n]);\n\n// Promise.race (first to complete)\nconst fastest = await Promise.race([\n  fetchData(),\n  fetchData(),\n]);'},{name:"PHP",lang:"php",code:'<?php\n// Fibers (PHP 8.1+)\n$fiber = new Fiber(function (): void {\n  $value = Fiber::suspend(\'fiber started\');\n  echo "Fiber resumed with: " . $value;\n});\n\n$result = $fiber->start();      // "fiber started"\n$fiber->resume(\'hello\');        // "Fiber resumed with: hello"\n\n// Parallel execution with pcntl_fork\n$pid = pcntl_fork();\nif ($pid == 0) {\n  // Child process\n  echo "Child process\\n";\n  exit(0);\n} else {\n  // Parent process\n  pcntl_wait($status);\n  echo "Parent process\\n";\n}\n\n// ReactPHP (event loop)\n// composer require react/event-loop\n$loop = React\\EventLoop\\Loop::get();\n$loop->addTimer(1.0, function () {\n  echo "Timer fired!\\n";\n});\n$loop->run();'},{name:"Rust",lang:"rust",code:'// Async/await with tokio\nuse tokio;\n\nasync fn fetch_data() -> String {\n  tokio::time::sleep(\n      tokio::time::Duration::from_secs(1)\n  ).await;\n  "data".to_string()\n}\n\n#[tokio::main]\nasync fn main() {\n  let result = fetch_data().await;\n  println!("{}", result);\n}\n\n// Parallel execution with join!\nlet (a, b) = tokio::join!(\n  fetch_data(),\n  fetch_data(),\n);\n\n// Spawning tasks\nlet handle = tokio::spawn(async {\n  fetch_data().await\n});\nlet result = handle.await.unwrap();'},{name:"Go",lang:"go",code:'// Goroutines (lightweight threads)\ngo func() {\n  fmt.Println("Hello from goroutine")\n}()\n\n// Channels for communication\nch := make(chan string)\n\ngo func() {\n  ch <- "hello"  // Send\n}()\n\nmsg := <-ch  // Receive\nfmt.Println(msg)\n\n// Select (multiplexing channels)\nselect {\ncase msg := <-ch1:\n  fmt.Println("From ch1:", msg)\ncase msg := <-ch2:\n  fmt.Println("From ch2:", msg)\ncase <-time.After(time.Second):\n  fmt.Println("Timeout")\n}\n\n// WaitGroup for synchronization\nvar wg sync.WaitGroup\nfor i := 0; i < 5; i++ {\n  wg.Add(1)\n  go func(id int) {\n      defer wg.Done()\n      fmt.Println("Worker", id)\n  }(i)\n}\nwg.Wait()'},{name:"Python",lang:"python",code:'import asyncio\n\n# Async/await\nasync def fetch_data():\n  await asyncio.sleep(1)\n  return "data"\n\nasync def main():\n  result = await fetch_data()\n  print(result)\n\nasyncio.run(main())\n\n# Parallel execution with gather\nasync def main():\n  a, b = await asyncio.gather(\n      fetch_data(),\n      fetch_data(),\n  )\n\n# Threading\nimport threading\n\ndef worker():\n  print("Worker thread")\n\nthread = threading.Thread(target=worker)\nthread.start()\nthread.join()\n\n# Multiprocessing\nfrom multiprocessing import Process\n\ndef worker():\n  print("Worker process")\n\np = Process(target=worker)\np.start()\np.join()'},{name:"Zig",lang:"zig",code:'const std = @import("std");\n\n// Threads\nfn worker(id: usize) void {\n  std.debug.print("Worker {}\\n", .{id});\n}\n\npub fn main() !void {\n  // Spawn threads\n  var threads: [5]std.Thread = undefined;\n  for (&threads, 0..) |*t, i| {\n      t.* = try std.Thread.spawn(.{}, worker, .{i});\n  }\n\n  // Join all threads\n  for (threads) |t| {\n      t.join();\n  }\n}\n\n// Async I/O with io_uring (Linux)\n// Zig provides low-level async through evented I/O\n// using std.event and std.io frameworks\n\n// Mutex for synchronization\nvar mutex = std.Thread.Mutex{};\nmutex.lock();\ndefer mutex.unlock();\n// critical section'},{name:"C#",lang:"csharp",code:'// Async/await\nasync Task<string> FetchDataAsync()\n{\n  await Task.Delay(1000);\n  return "data";\n}\n\nasync Task Main()\n{\n  string result = await FetchDataAsync();\n  Console.WriteLine(result);\n}\n\n// Parallel execution\nvar (a, b) = await (\n  FetchDataAsync(),\n  FetchDataAsync()\n);\n\n// Task.WhenAll\nvar results = await Task.WhenAll(\n  FetchDataAsync(),\n  FetchDataAsync()\n);\n\n// Parallel.ForEach\nParallel.ForEach(items, item =>\n{\n  Process(item);\n});\n\n// Threads\nvar thread = new Thread(() =>\n{\n  Console.WriteLine("Worker thread");\n});\nthread.Start();\nthread.Join();'},{name:"C++",lang:"cpp",code:'#include <thread>\n#include <future>\n#include <mutex>\n\n// Threads\nstd::thread t([]() {\n  std::cout << "Worker thread" << std::endl;\n});\nt.join();\n\n// Async/future\nauto future = std::async(std::launch::async, []() {\n  std::this_thread::sleep_for(\n      std::chrono::seconds(1)\n  );\n  return std::string("data");\n});\nstd::string result = future.get();\n\n// Mutex\nstd::mutex mtx;\n{\n  std::lock_guard<std::mutex> lock(mtx);\n  // critical section\n}\n\n// Condition variables\nstd::condition_variable cv;\nstd::unique_lock<std::mutex> lk(mtx);\ncv.wait(lk, []{ return ready; });'},{name:"C",lang:"c",code:'#include <pthread.h>\n\n// POSIX threads\nvoid* worker(void* arg) {\n  int id = *(int*)arg;\n  printf("Worker %d\\n", id);\n  return NULL;\n}\n\nint main() {\n  pthread_t threads[5];\n  int ids[5];\n\n  for (int i = 0; i < 5; i++) {\n      ids[i] = i;\n      pthread_create(&threads[i], NULL,\n                     worker, &ids[i]);\n  }\n\n  for (int i = 0; i < 5; i++) {\n      pthread_join(threads[i], NULL);\n  }\n\n  return 0;\n}\n\n// Mutex\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_lock(&mutex);\n// critical section\npthread_mutex_unlock(&mutex);'},{name:"Java",lang:"java",code:'// CompletableFuture (async)\nCompletableFuture<String> future =\n  CompletableFuture.supplyAsync(() -> {\n      Thread.sleep(1000);\n      return "data";\n  });\n\nString result = future.get();\n\n// Parallel streams\nList<Integer> results = list.parallelStream()\n  .map(x -> x * 2)\n  .collect(Collectors.toList());\n\n// Virtual threads (Java 21+)\nThread.startVirtualThread(() -> {\n  System.out.println("Virtual thread");\n});\n\n// ExecutorService\nExecutorService executor =\n  Executors.newFixedThreadPool(4);\nFuture<String> f = executor.submit(() -> "result");\nexecutor.shutdown();\n\n// Threads\nThread thread = new Thread(() -> {\n  System.out.println("Worker");\n});\nthread.start();\nthread.join();'},{name:"Ruby",lang:"ruby",code:'# Threads\nthread = Thread.new do\nputs "Worker thread"\nend\nthread.join\n\n# Multiple threads\nthreads = 5.times.map do |i|\nThread.new(i) do |id|\n  puts "Worker #{id}"\nend\nend\nthreads.each(&:join)\n\n# Mutex\nmutex = Mutex.new\nmutex.synchronize do\n# critical section\nend\n\n# Fibers (cooperative concurrency)\nfiber = Fiber.new do\nFiber.yield "first"\nFiber.yield "second"\n"third"\nend\n\nputs fiber.resume  # "first"\nputs fiber.resume  # "second"\n\n# Ractor (Ruby 3.0+ true parallelism)\nractor = Ractor.new do\nRactor.yield "hello from ractor"\nend\nputs ractor.take'},{name:"Swift",lang:"swift",code:'// Structured concurrency (Swift 5.5+)\nfunc fetchData() async -> String {\n  try? await Task.sleep(nanoseconds: 1_000_000_000)\n  return "data"\n}\n\n// Async/await\nTask {\n  let result = await fetchData()\n  print(result)\n}\n\n// Parallel execution with async let\nasync let a = fetchData()\nasync let b = fetchData()\nlet results = await (a, b)\n\n// TaskGroup\nawait withTaskGroup(of: String.self) { group in\n  for i in 0..<5 {\n      group.addTask {\n          return await fetchData()\n      }\n  }\n  for await result in group {\n      print(result)\n  }\n}\n\n// Actors (thread-safe state)\nactor Counter {\n  private var count = 0\n  func increment() { count += 1 }\n  func getCount() -> Int { count }\n}'}]}),"\n",(0,r.jsx)(e.h2,{id:"seguridad-de-hilos-y-sincronizaci\xf3n",children:"Seguridad de Hilos y Sincronizaci\xf3n"}),"\n",(0,r.jsx)(c.A,{languages:[{name:"JavaScript",lang:"javascript",code:"// JavaScript is single-threaded (event loop)\n// No shared memory issues in main thread\n\n// Web Workers (browser) / Worker Threads (Node.js)\nconst { Worker } = require('worker_threads');\n\nconst worker = new Worker('./worker.js');\nworker.postMessage({ data: 'hello' });\nworker.on('message', (msg) => {\n  console.log('From worker:', msg);\n});\n\n// SharedArrayBuffer (shared memory)\nconst buffer = new SharedArrayBuffer(1024);\nconst view = new Int32Array(buffer);\nAtomics.add(view, 0, 1);  // Atomic operation"},{name:"PHP",lang:"php",code:'<?php\n// PHP is typically single-threaded per request\n// Use extensions for true threading\n\n// Shared memory with shmop\n$shm = shmop_open(123, "c", 0644, 100);\nshmop_write($shm, "data", 0);\n$data = shmop_read($shm, 0, 4);\nshmop_delete($shm);\n\n// Semaphores\n$sem = sem_get(1234);\nsem_acquire($sem);\n// critical section\nsem_release($sem);'},{name:"Rust",lang:"rust",code:'use std::sync::{Arc, Mutex, RwLock};\n\n// Mutex (mutual exclusion)\nlet counter = Arc::new(Mutex::new(0));\n\nlet handles: Vec<_> = (0..5).map(|_| {\n  let counter = Arc::clone(&counter);\n  std::thread::spawn(move || {\n      let mut num = counter.lock().unwrap();\n      *num += 1;\n  })\n}).collect();\n\nfor handle in handles {\n  handle.join().unwrap();\n}\n\n// RwLock (multiple readers, one writer)\nlet data = Arc::new(RwLock::new(vec![1, 2, 3]));\nlet read = data.read().unwrap();\n// Channels\nuse std::sync::mpsc;\nlet (tx, rx) = mpsc::channel();\ntx.send("hello").unwrap();\nlet msg = rx.recv().unwrap();'},{name:"Go",lang:"go",code:'import "sync"\n\n// Mutex\nvar mu sync.Mutex\nmu.Lock()\n// critical section\nmu.Unlock()\n\n// RWMutex\nvar rw sync.RWMutex\nrw.RLock()   // Read lock\nrw.RUnlock()\nrw.Lock()    // Write lock\nrw.Unlock()\n\n// Atomic operations\nimport "sync/atomic"\nvar counter int64\natomic.AddInt64(&counter, 1)\nval := atomic.LoadInt64(&counter)\n\n// Once (run exactly once)\nvar once sync.Once\nonce.Do(func() {\n  fmt.Println("Only once")\n})'},{name:"Python",lang:"python",code:'import threading\n\n# Lock\nlock = threading.Lock()\nwith lock:\n  # critical section\n  pass\n\n# RLock (reentrant)\nrlock = threading.RLock()\n\n# Semaphore\nsem = threading.Semaphore(3)\nwith sem:\n  # max 3 concurrent\n  pass\n\n# Event\nevent = threading.Event()\nevent.set()    # Signal\nevent.wait()   # Wait for signal\nevent.clear()  # Reset\n\n# Queue (thread-safe)\nfrom queue import Queue\nq = Queue()\nq.put("item")\nitem = q.get()'},{name:"Zig",lang:"zig",code:'const std = @import("std");\n\n// Mutex\nvar mutex = std.Thread.Mutex{};\nmutex.lock();\ndefer mutex.unlock();\n// critical section\n\n// Atomic operations\nvar counter = std.atomic.Value(u32).init(0);\n_ = counter.fetchAdd(1, .seq_cst);\nconst val = counter.load(.seq_cst);\n\n// ResetEvent (signaling)\nvar event = std.Thread.ResetEvent{};\nevent.set();   // Signal\nevent.wait();  // Wait'},{name:"C#",lang:"csharp",code:'// Lock\nprivate readonly object _lock = new();\n\nlock (_lock)\n{\n  // critical section\n}\n\n// SemaphoreSlim\nvar sem = new SemaphoreSlim(3);\nawait sem.WaitAsync();\ntry { /* work */ }\nfinally { sem.Release(); }\n\n// Channel (producer-consumer)\nvar channel = Channel.CreateUnbounded<string>();\nawait channel.Writer.WriteAsync("item");\nvar item = await channel.Reader.ReadAsync();\n\n// Interlocked (atomic)\nint counter = 0;\nInterlocked.Increment(ref counter);'},{name:"C++",lang:"cpp",code:"#include <mutex>\n#include <atomic>\n#include <shared_mutex>\n\n// Mutex with lock_guard\nstd::mutex mtx;\n{\n  std::lock_guard<std::mutex> lock(mtx);\n  // critical section\n}\n\n// shared_mutex (read-write lock)\nstd::shared_mutex rw_mtx;\n{\n  std::shared_lock lock(rw_mtx);  // Read\n}\n{\n  std::unique_lock lock(rw_mtx);  // Write\n}\n\n// Atomic\nstd::atomic<int> counter{0};\ncounter.fetch_add(1);\nint val = counter.load();"},{name:"C",lang:"c",code:"#include <pthread.h>\n#include <stdatomic.h>\n\n// Mutex\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_lock(&mutex);\n// critical section\npthread_mutex_unlock(&mutex);\n\n// Read-write lock\npthread_rwlock_t rwlock = PTHREAD_RWLOCK_INITIALIZER;\npthread_rwlock_rdlock(&rwlock);  // Read\npthread_rwlock_unlock(&rwlock);\npthread_rwlock_wrlock(&rwlock);  // Write\npthread_rwlock_unlock(&rwlock);\n\n// Atomic (C11)\natomic_int counter = 0;\natomic_fetch_add(&counter, 1);\nint val = atomic_load(&counter);"},{name:"Java",lang:"java",code:'// synchronized\nsynchronized (this) {\n  // critical section\n}\n\n// ReentrantLock\nReentrantLock lock = new ReentrantLock();\nlock.lock();\ntry { /* work */ }\nfinally { lock.unlock(); }\n\n// AtomicInteger\nAtomicInteger counter = new AtomicInteger(0);\ncounter.incrementAndGet();\nint val = counter.get();\n\n// ConcurrentHashMap\nConcurrentHashMap<String, Integer> map =\n  new ConcurrentHashMap<>();\nmap.put("key", 1);\n\n// BlockingQueue\nBlockingQueue<String> queue =\n  new LinkedBlockingQueue<>();\nqueue.put("item");\nString item = queue.take();'},{name:"Ruby",lang:"ruby",code:"# Mutex\nmutex = Mutex.new\nmutex.synchronize do\n# critical section\nend\n\n# Queue (thread-safe)\nrequire 'thread'\nqueue = Queue.new\nqueue << \"item\"\nitem = queue.pop\n\n# ConditionVariable\ncv = ConditionVariable.new\nmutex.synchronize do\ncv.wait(mutex)  # Wait\nend\nmutex.synchronize do\ncv.signal        # Wake one\ncv.broadcast     # Wake all\nend\n\n# Concurrent::Ruby gem\n# gem install concurrent-ruby\nrequire 'concurrent'\nfuture = Concurrent::Future.execute { 42 }\nputs future.value"},{name:"Swift",lang:"swift",code:"// Actors (built-in thread safety)\nactor BankAccount {\n  private var balance: Double = 0\n\n  func deposit(_ amount: Double) {\n      balance += amount\n  }\n\n  func getBalance() -> Double {\n      return balance\n  }\n}\n\nlet account = BankAccount()\nawait account.deposit(100)\nlet balance = await account.getBalance()\n\n// DispatchQueue\nDispatchQueue.global().async {\n  // Background work\n  DispatchQueue.main.async {\n      // Update UI\n  }\n}\n\n// NSLock\nlet lock = NSLock()\nlock.lock()\n// critical section\nlock.unlock()"}]}),"\n",(0,r.jsx)(e.h2,{id:"puntos-clave",children:"Puntos Clave"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Los modelos de concurrencia var\xedan ampliamente"})," -- Go usa goroutines con canales (estilo CSP): ",(0,r.jsx)(e.code,{children:'go func() { ch <- "hello" }'})," y ",(0,r.jsx)(e.code,{children:"msg := <-ch"}),". JavaScript, Python, Rust, C# y Swift usan async/await: ",(0,r.jsx)(e.code,{children:"async def fetch_data()"})," en Python, ",(0,r.jsx)(e.code,{children:"async fn fetch_data()"})," en Rust con tokio, ",(0,r.jsx)(e.code,{children:"async Task<string> FetchDataAsync()"})," en C#. C, C++ y Java usan hilos tradicionales del sistema operativo con ",(0,r.jsx)(e.code,{children:"pthread_create"}),", ",(0,r.jsx)(e.code,{children:"std::thread"})," o ",(0,r.jsx)(e.code,{children:"Thread.start()"}),", m\xe1s mutexes para sincronizaci\xf3n. Las goroutines son ligeras (millones posibles); los hilos son m\xe1s pesados. Async/await es adecuado para trabajo limitado por E/S; los hilos son adecuados para paralelismo limitado por CPU. Elige Go para concurrencia simple; elige async/await para servidores con mucha E/S; elige hilos cuando necesites verdadero paralelismo y control."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"La comunicaci\xf3n basada en canales es de primera clase en Go"})," -- Los canales integrados de Go y ",(0,r.jsx)(e.code,{children:"select"})," hacen que los patrones productor-consumidor sean idiom\xe1ticos: ",(0,r.jsx)(e.code,{children:"ch := make(chan string)"}),", ",(0,r.jsx)(e.code,{children:'ch <- "msg"'}),", ",(0,r.jsx)(e.code,{children:"msg := <-ch"})," y ",(0,r.jsx)(e.code,{children:"select { case msg := <-ch1: ... case msg := <-ch2: ... }"}),". Rust ofrece ",(0,r.jsx)(e.code,{children:"std::sync::mpsc::channel()"})," y C# tiene ",(0,r.jsx)(e.code,{children:"Channel.CreateUnbounded<T>()"}),', pero son caracter\xedsticas de biblioteca. El dise\xf1o de Go promueve "compartir memoria comunic\xe1ndose" en lugar de mutexes. Si construyes pipelines, pools de workers o sistemas orientados a eventos, los canales de Go son los m\xe1s ergon\xf3micos; Rust y C# proporcionan un poder similar con m\xe1s configuraci\xf3n.']}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Go y Rust sobresalen en concurrencia"})," -- Las goroutines de Go son ligeras (pilas de 2KB, multiplexadas sobre hilos del SO) y f\xe1ciles de crear: ",(0,r.jsx)(e.code,{children:"go worker(id)"}),". El modelo de propiedad de Rust previene carreras de datos en tiempo de compilaci\xf3n: el compilador rechaza compartir estado mutable entre hilos sin sincronizaci\xf3n. Por ejemplo, ",(0,r.jsx)(e.code,{children:"Arc<Mutex<i32>>"})," en Rust asegura acceso compartido seguro. Go depende de canales y disciplina; Rust impone seguridad est\xe1ticamente. Elige Go cuando quieras concurrencia simple y r\xe1pida con m\xednima fricci\xf3n; elige Rust cuando necesites m\xe1xima seguridad y rendimiento sin recolector de basura."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Swift introduce actores"})," -- Los actores proporcionan estado compartido seguro entre hilos al serializar el acceso: ",(0,r.jsx)(e.code,{children:"actor Counter { private var count = 0; func increment() { count += 1 } }"})," -- todos los m\xe9todos se ejecutan en serie, as\xed que no hay carreras de datos. Llamas con ",(0,r.jsx)(e.code,{children:"await account.deposit(100)"}),". Esto reemplaza los patrones manuales de ",(0,r.jsx)(e.code,{children:"Mutex"}),"/",(0,r.jsx)(e.code,{children:"Lock"}),". Los actores de Swift se integran con async/await y la concurrencia estructurada. Si construyes sistemas concurrentes en Swift (p. ej., iOS/macOS), prefiere actores sobre bloqueo manual; para otros lenguajes, usa mutexes o dise\xf1os basados en canales."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"JavaScript es de un solo hilo"})," -- El bucle de eventos maneja la asincron\xeda mediante callbacks y Promises: ",(0,r.jsx)(e.code,{children:"await fetch('/api')"})," no bloquea el hilo; cede hasta que llega la respuesta. El verdadero paralelismo requiere Web Workers (navegador) o Worker Threads (Node.js) con ",(0,r.jsx)(e.code,{children:"postMessage"})," para comunicaci\xf3n. El trabajo pesado de CPU (hashing, procesamiento de im\xe1genes) bloquea el hilo principal; desc\xe1rgalo a workers. Para servidores Node.js con mucha E/S, async/await es suficiente; para tareas limitadas por CPU, agrega workers o considera un lenguaje multi-hilo como Go o Rust."]}),"\n"]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(u,{...n})}):u(n)}}}]);