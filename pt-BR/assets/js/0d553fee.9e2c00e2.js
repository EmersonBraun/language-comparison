"use strict";(globalThis.webpackChunklanguage_comparison_docs=globalThis.webpackChunklanguage_comparison_docs||[]).push([[672],{5735(n,e,a){a.r(e),a.d(e,{assets:()=>d,contentTitle:()=>i,default:()=>m,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"concurrency-async","title":"Concorr\xeancia & Async","description":"Modelos de concorr\xeancia -- async/await, threads, goroutines e atores em 12 linguagens","source":"@site/i18n/pt-BR/docusaurus-plugin-content-docs/current/concurrency-async.md","sourceDirName":".","slug":"/concurrency-async","permalink":"/language-comparison/pt-BR/docs/concurrency-async","draft":false,"unlisted":false,"editUrl":"https://github.com/EmersonBraun/language-comparison/tree/main/docs/concurrency-async.md","tags":[],"version":"current","sidebarPosition":24,"frontMatter":{"sidebar_position":24,"description":"Modelos de concorr\xeancia -- async/await, threads, goroutines e atores em 12 linguagens","keywords":["concorr\xeancia","async","await","threads","goroutines","atores","paralelo"]},"sidebar":"tutorialSidebar","previous":{"title":"Null Safety & Optionals","permalink":"/language-comparison/pt-BR/docs/null-safety"},"next":{"title":"Memory Management","permalink":"/language-comparison/pt-BR/docs/memory-management"}}');var r=a(4848),o=a(8453),c=a(6153);const s={sidebar_position:24,description:"Modelos de concorr\xeancia -- async/await, threads, goroutines e atores em 12 linguagens",keywords:["concorr\xeancia","async","await","threads","goroutines","atores","paralelo"]},i="Concorr\xeancia & Async",d={},l=[{value:"Execu\xe7\xe3o B\xe1sica Async / Concorrente",id:"execu\xe7\xe3o-b\xe1sica-async--concorrente",level:2},{value:"Seguran\xe7a de Threads &amp; Sincroniza\xe7\xe3o",id:"seguran\xe7a-de-threads--sincroniza\xe7\xe3o",level:2},{value:"Principais Conclus\xf5es",id:"principais-conclus\xf5es",level:2}];function u(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"concorr\xeancia--async",children:"Concorr\xeancia & Async"})}),"\n",(0,r.jsx)(e.p,{children:"Os modelos de concorr\xeancia s\xe3o um dos maiores diferenciadores entre linguagens de programa\xe7\xe3o. Veja como diferentes linguagens lidam com programa\xe7\xe3o ass\xedncrona, threads e execu\xe7\xe3o concorrente."}),"\n","\n",(0,r.jsx)(e.h2,{id:"execu\xe7\xe3o-b\xe1sica-async--concorrente",children:"Execu\xe7\xe3o B\xe1sica Async / Concorrente"}),"\n",(0,r.jsx)(c.A,{languages:[{name:"JavaScript",lang:"javascript",code:'// Promises\nconst fetchData = () => {\n  return new Promise((resolve) => {\n      setTimeout(() => resolve("data"), 1000);\n  });\n};\n\n// Async/await\nasync function main() {\n  const result = await fetchData();\n  console.log(result);\n}\n\n// Promise.all (parallel)\nconst [a, b] = await Promise.all([\n  fetchData(),\n  fetchData(),\n]);\n\n// Promise.race (first to complete)\nconst fastest = await Promise.race([\n  fetchData(),\n  fetchData(),\n]);'},{name:"PHP",lang:"php",code:'<?php\n// Fibers (PHP 8.1+)\n$fiber = new Fiber(function (): void {\n  $value = Fiber::suspend(\'fiber started\');\n  echo "Fiber resumed with: " . $value;\n});\n\n$result = $fiber->start();      // "fiber started"\n$fiber->resume(\'hello\');        // "Fiber resumed with: hello"\n\n// Parallel execution with pcntl_fork\n$pid = pcntl_fork();\nif ($pid == 0) {\n  // Child process\n  echo "Child process\\n";\n  exit(0);\n} else {\n  // Parent process\n  pcntl_wait($status);\n  echo "Parent process\\n";\n}\n\n// ReactPHP (event loop)\n// composer require react/event-loop\n$loop = React\\EventLoop\\Loop::get();\n$loop->addTimer(1.0, function () {\n  echo "Timer fired!\\n";\n});\n$loop->run();'},{name:"Rust",lang:"rust",code:'// Async/await with tokio\nuse tokio;\n\nasync fn fetch_data() -> String {\n  tokio::time::sleep(\n      tokio::time::Duration::from_secs(1)\n  ).await;\n  "data".to_string()\n}\n\n#[tokio::main]\nasync fn main() {\n  let result = fetch_data().await;\n  println!("{}", result);\n}\n\n// Parallel execution with join!\nlet (a, b) = tokio::join!(\n  fetch_data(),\n  fetch_data(),\n);\n\n// Spawning tasks\nlet handle = tokio::spawn(async {\n  fetch_data().await\n});\nlet result = handle.await.unwrap();'},{name:"Go",lang:"go",code:'// Goroutines (lightweight threads)\ngo func() {\n  fmt.Println("Hello from goroutine")\n}()\n\n// Channels for communication\nch := make(chan string)\n\ngo func() {\n  ch <- "hello"  // Send\n}()\n\nmsg := <-ch  // Receive\nfmt.Println(msg)\n\n// Select (multiplexing channels)\nselect {\ncase msg := <-ch1:\n  fmt.Println("From ch1:", msg)\ncase msg := <-ch2:\n  fmt.Println("From ch2:", msg)\ncase <-time.After(time.Second):\n  fmt.Println("Timeout")\n}\n\n// WaitGroup for synchronization\nvar wg sync.WaitGroup\nfor i := 0; i < 5; i++ {\n  wg.Add(1)\n  go func(id int) {\n      defer wg.Done()\n      fmt.Println("Worker", id)\n  }(i)\n}\nwg.Wait()'},{name:"Python",lang:"python",code:'import asyncio\n\n# Async/await\nasync def fetch_data():\n  await asyncio.sleep(1)\n  return "data"\n\nasync def main():\n  result = await fetch_data()\n  print(result)\n\nasyncio.run(main())\n\n# Parallel execution with gather\nasync def main():\n  a, b = await asyncio.gather(\n      fetch_data(),\n      fetch_data(),\n  )\n\n# Threading\nimport threading\n\ndef worker():\n  print("Worker thread")\n\nthread = threading.Thread(target=worker)\nthread.start()\nthread.join()\n\n# Multiprocessing\nfrom multiprocessing import Process\n\ndef worker():\n  print("Worker process")\n\np = Process(target=worker)\np.start()\np.join()'},{name:"Zig",lang:"zig",code:'const std = @import("std");\n\n// Threads\nfn worker(id: usize) void {\n  std.debug.print("Worker {}\\n", .{id});\n}\n\npub fn main() !void {\n  // Spawn threads\n  var threads: [5]std.Thread = undefined;\n  for (&threads, 0..) |*t, i| {\n      t.* = try std.Thread.spawn(.{}, worker, .{i});\n  }\n\n  // Join all threads\n  for (threads) |t| {\n      t.join();\n  }\n}\n\n// Async I/O with io_uring (Linux)\n// Zig provides low-level async through evented I/O\n// using std.event and std.io frameworks\n\n// Mutex for synchronization\nvar mutex = std.Thread.Mutex{};\nmutex.lock();\ndefer mutex.unlock();\n// critical section'},{name:"C#",lang:"csharp",code:'// Async/await\nasync Task<string> FetchDataAsync()\n{\n  await Task.Delay(1000);\n  return "data";\n}\n\nasync Task Main()\n{\n  string result = await FetchDataAsync();\n  Console.WriteLine(result);\n}\n\n// Parallel execution\nvar (a, b) = await (\n  FetchDataAsync(),\n  FetchDataAsync()\n);\n\n// Task.WhenAll\nvar results = await Task.WhenAll(\n  FetchDataAsync(),\n  FetchDataAsync()\n);\n\n// Parallel.ForEach\nParallel.ForEach(items, item =>\n{\n  Process(item);\n});\n\n// Threads\nvar thread = new Thread(() =>\n{\n  Console.WriteLine("Worker thread");\n});\nthread.Start();\nthread.Join();'},{name:"C++",lang:"cpp",code:'#include <thread>\n#include <future>\n#include <mutex>\n\n// Threads\nstd::thread t([]() {\n  std::cout << "Worker thread" << std::endl;\n});\nt.join();\n\n// Async/future\nauto future = std::async(std::launch::async, []() {\n  std::this_thread::sleep_for(\n      std::chrono::seconds(1)\n  );\n  return std::string("data");\n});\nstd::string result = future.get();\n\n// Mutex\nstd::mutex mtx;\n{\n  std::lock_guard<std::mutex> lock(mtx);\n  // critical section\n}\n\n// Condition variables\nstd::condition_variable cv;\nstd::unique_lock<std::mutex> lk(mtx);\ncv.wait(lk, []{ return ready; });'},{name:"C",lang:"c",code:'#include <pthread.h>\n\n// POSIX threads\nvoid* worker(void* arg) {\n  int id = *(int*)arg;\n  printf("Worker %d\\n", id);\n  return NULL;\n}\n\nint main() {\n  pthread_t threads[5];\n  int ids[5];\n\n  for (int i = 0; i < 5; i++) {\n      ids[i] = i;\n      pthread_create(&threads[i], NULL,\n                     worker, &ids[i]);\n  }\n\n  for (int i = 0; i < 5; i++) {\n      pthread_join(threads[i], NULL);\n  }\n\n  return 0;\n}\n\n// Mutex\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_lock(&mutex);\n// critical section\npthread_mutex_unlock(&mutex);'},{name:"Java",lang:"java",code:'// CompletableFuture (async)\nCompletableFuture<String> future =\n  CompletableFuture.supplyAsync(() -> {\n      Thread.sleep(1000);\n      return "data";\n  });\n\nString result = future.get();\n\n// Parallel streams\nList<Integer> results = list.parallelStream()\n  .map(x -> x * 2)\n  .collect(Collectors.toList());\n\n// Virtual threads (Java 21+)\nThread.startVirtualThread(() -> {\n  System.out.println("Virtual thread");\n});\n\n// ExecutorService\nExecutorService executor =\n  Executors.newFixedThreadPool(4);\nFuture<String> f = executor.submit(() -> "result");\nexecutor.shutdown();\n\n// Threads\nThread thread = new Thread(() -> {\n  System.out.println("Worker");\n});\nthread.start();\nthread.join();'},{name:"Ruby",lang:"ruby",code:'# Threads\nthread = Thread.new do\nputs "Worker thread"\nend\nthread.join\n\n# Multiple threads\nthreads = 5.times.map do |i|\nThread.new(i) do |id|\n  puts "Worker #{id}"\nend\nend\nthreads.each(&:join)\n\n# Mutex\nmutex = Mutex.new\nmutex.synchronize do\n# critical section\nend\n\n# Fibers (cooperative concurrency)\nfiber = Fiber.new do\nFiber.yield "first"\nFiber.yield "second"\n"third"\nend\n\nputs fiber.resume  # "first"\nputs fiber.resume  # "second"\n\n# Ractor (Ruby 3.0+ true parallelism)\nractor = Ractor.new do\nRactor.yield "hello from ractor"\nend\nputs ractor.take'},{name:"Swift",lang:"swift",code:'// Structured concurrency (Swift 5.5+)\nfunc fetchData() async -> String {\n  try? await Task.sleep(nanoseconds: 1_000_000_000)\n  return "data"\n}\n\n// Async/await\nTask {\n  let result = await fetchData()\n  print(result)\n}\n\n// Parallel execution with async let\nasync let a = fetchData()\nasync let b = fetchData()\nlet results = await (a, b)\n\n// TaskGroup\nawait withTaskGroup(of: String.self) { group in\n  for i in 0..<5 {\n      group.addTask {\n          return await fetchData()\n      }\n  }\n  for await result in group {\n      print(result)\n  }\n}\n\n// Actors (thread-safe state)\nactor Counter {\n  private var count = 0\n  func increment() { count += 1 }\n  func getCount() -> Int { count }\n}'}]}),"\n",(0,r.jsx)(e.h2,{id:"seguran\xe7a-de-threads--sincroniza\xe7\xe3o",children:"Seguran\xe7a de Threads & Sincroniza\xe7\xe3o"}),"\n",(0,r.jsx)(c.A,{languages:[{name:"JavaScript",lang:"javascript",code:"// JavaScript is single-threaded (event loop)\n// No shared memory issues in main thread\n\n// Web Workers (browser) / Worker Threads (Node.js)\nconst { Worker } = require('worker_threads');\n\nconst worker = new Worker('./worker.js');\nworker.postMessage({ data: 'hello' });\nworker.on('message', (msg) => {\n  console.log('From worker:', msg);\n});\n\n// SharedArrayBuffer (shared memory)\nconst buffer = new SharedArrayBuffer(1024);\nconst view = new Int32Array(buffer);\nAtomics.add(view, 0, 1);  // Atomic operation"},{name:"PHP",lang:"php",code:'<?php\n// PHP is typically single-threaded per request\n// Use extensions for true threading\n\n// Shared memory with shmop\n$shm = shmop_open(123, "c", 0644, 100);\nshmop_write($shm, "data", 0);\n$data = shmop_read($shm, 0, 4);\nshmop_delete($shm);\n\n// Semaphores\n$sem = sem_get(1234);\nsem_acquire($sem);\n// critical section\nsem_release($sem);'},{name:"Rust",lang:"rust",code:'use std::sync::{Arc, Mutex, RwLock};\n\n// Mutex (mutual exclusion)\nlet counter = Arc::new(Mutex::new(0));\n\nlet handles: Vec<_> = (0..5).map(|_| {\n  let counter = Arc::clone(&counter);\n  std::thread::spawn(move || {\n      let mut num = counter.lock().unwrap();\n      *num += 1;\n  })\n}).collect();\n\nfor handle in handles {\n  handle.join().unwrap();\n}\n\n// RwLock (multiple readers, one writer)\nlet data = Arc::new(RwLock::new(vec![1, 2, 3]));\nlet read = data.read().unwrap();\n// Channels\nuse std::sync::mpsc;\nlet (tx, rx) = mpsc::channel();\ntx.send("hello").unwrap();\nlet msg = rx.recv().unwrap();'},{name:"Go",lang:"go",code:'import "sync"\n\n// Mutex\nvar mu sync.Mutex\nmu.Lock()\n// critical section\nmu.Unlock()\n\n// RWMutex\nvar rw sync.RWMutex\nrw.RLock()   // Read lock\nrw.RUnlock()\nrw.Lock()    // Write lock\nrw.Unlock()\n\n// Atomic operations\nimport "sync/atomic"\nvar counter int64\natomic.AddInt64(&counter, 1)\nval := atomic.LoadInt64(&counter)\n\n// Once (run exactly once)\nvar once sync.Once\nonce.Do(func() {\n  fmt.Println("Only once")\n})'},{name:"Python",lang:"python",code:'import threading\n\n# Lock\nlock = threading.Lock()\nwith lock:\n  # critical section\n  pass\n\n# RLock (reentrant)\nrlock = threading.RLock()\n\n# Semaphore\nsem = threading.Semaphore(3)\nwith sem:\n  # max 3 concurrent\n  pass\n\n# Event\nevent = threading.Event()\nevent.set()    # Signal\nevent.wait()   # Wait for signal\nevent.clear()  # Reset\n\n# Queue (thread-safe)\nfrom queue import Queue\nq = Queue()\nq.put("item")\nitem = q.get()'},{name:"Zig",lang:"zig",code:'const std = @import("std");\n\n// Mutex\nvar mutex = std.Thread.Mutex{};\nmutex.lock();\ndefer mutex.unlock();\n// critical section\n\n// Atomic operations\nvar counter = std.atomic.Value(u32).init(0);\n_ = counter.fetchAdd(1, .seq_cst);\nconst val = counter.load(.seq_cst);\n\n// ResetEvent (signaling)\nvar event = std.Thread.ResetEvent{};\nevent.set();   // Signal\nevent.wait();  // Wait'},{name:"C#",lang:"csharp",code:'// Lock\nprivate readonly object _lock = new();\n\nlock (_lock)\n{\n  // critical section\n}\n\n// SemaphoreSlim\nvar sem = new SemaphoreSlim(3);\nawait sem.WaitAsync();\ntry { /* work */ }\nfinally { sem.Release(); }\n\n// Channel (producer-consumer)\nvar channel = Channel.CreateUnbounded<string>();\nawait channel.Writer.WriteAsync("item");\nvar item = await channel.Reader.ReadAsync();\n\n// Interlocked (atomic)\nint counter = 0;\nInterlocked.Increment(ref counter);'},{name:"C++",lang:"cpp",code:"#include <mutex>\n#include <atomic>\n#include <shared_mutex>\n\n// Mutex with lock_guard\nstd::mutex mtx;\n{\n  std::lock_guard<std::mutex> lock(mtx);\n  // critical section\n}\n\n// shared_mutex (read-write lock)\nstd::shared_mutex rw_mtx;\n{\n  std::shared_lock lock(rw_mtx);  // Read\n}\n{\n  std::unique_lock lock(rw_mtx);  // Write\n}\n\n// Atomic\nstd::atomic<int> counter{0};\ncounter.fetch_add(1);\nint val = counter.load();"},{name:"C",lang:"c",code:"#include <pthread.h>\n#include <stdatomic.h>\n\n// Mutex\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_lock(&mutex);\n// critical section\npthread_mutex_unlock(&mutex);\n\n// Read-write lock\npthread_rwlock_t rwlock = PTHREAD_RWLOCK_INITIALIZER;\npthread_rwlock_rdlock(&rwlock);  // Read\npthread_rwlock_unlock(&rwlock);\npthread_rwlock_wrlock(&rwlock);  // Write\npthread_rwlock_unlock(&rwlock);\n\n// Atomic (C11)\natomic_int counter = 0;\natomic_fetch_add(&counter, 1);\nint val = atomic_load(&counter);"},{name:"Java",lang:"java",code:'// synchronized\nsynchronized (this) {\n  // critical section\n}\n\n// ReentrantLock\nReentrantLock lock = new ReentrantLock();\nlock.lock();\ntry { /* work */ }\nfinally { lock.unlock(); }\n\n// AtomicInteger\nAtomicInteger counter = new AtomicInteger(0);\ncounter.incrementAndGet();\nint val = counter.get();\n\n// ConcurrentHashMap\nConcurrentHashMap<String, Integer> map =\n  new ConcurrentHashMap<>();\nmap.put("key", 1);\n\n// BlockingQueue\nBlockingQueue<String> queue =\n  new LinkedBlockingQueue<>();\nqueue.put("item");\nString item = queue.take();'},{name:"Ruby",lang:"ruby",code:"# Mutex\nmutex = Mutex.new\nmutex.synchronize do\n# critical section\nend\n\n# Queue (thread-safe)\nrequire 'thread'\nqueue = Queue.new\nqueue << \"item\"\nitem = queue.pop\n\n# ConditionVariable\ncv = ConditionVariable.new\nmutex.synchronize do\ncv.wait(mutex)  # Wait\nend\nmutex.synchronize do\ncv.signal        # Wake one\ncv.broadcast     # Wake all\nend\n\n# Concurrent::Ruby gem\n# gem install concurrent-ruby\nrequire 'concurrent'\nfuture = Concurrent::Future.execute { 42 }\nputs future.value"},{name:"Swift",lang:"swift",code:"// Actors (built-in thread safety)\nactor BankAccount {\n  private var balance: Double = 0\n\n  func deposit(_ amount: Double) {\n      balance += amount\n  }\n\n  func getBalance() -> Double {\n      return balance\n  }\n}\n\nlet account = BankAccount()\nawait account.deposit(100)\nlet balance = await account.getBalance()\n\n// DispatchQueue\nDispatchQueue.global().async {\n  // Background work\n  DispatchQueue.main.async {\n      // Update UI\n  }\n}\n\n// NSLock\nlet lock = NSLock()\nlock.lock()\n// critical section\nlock.unlock()"}]}),"\n",(0,r.jsx)(e.h2,{id:"principais-conclus\xf5es",children:"Principais Conclus\xf5es"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Modelos de concorr\xeancia variam amplamente"})," -- Go usa goroutines com channels (estilo CSP): ",(0,r.jsx)(e.code,{children:'go func() { ch <- "hello" }'})," e ",(0,r.jsx)(e.code,{children:"msg := <-ch"}),". JavaScript, Python, Rust, C# e Swift usam async/await: ",(0,r.jsx)(e.code,{children:"async def fetch_data()"})," em Python, ",(0,r.jsx)(e.code,{children:"async fn fetch_data()"})," em Rust com tokio, ",(0,r.jsx)(e.code,{children:"async Task<string> FetchDataAsync()"})," em C#. C, C++ e Java usam threads tradicionais do SO com ",(0,r.jsx)(e.code,{children:"pthread_create"}),", ",(0,r.jsx)(e.code,{children:"std::thread"})," ou ",(0,r.jsx)(e.code,{children:"Thread.start()"}),", al\xe9m de mutexes para sincroniza\xe7\xe3o. Goroutines s\xe3o leves (milh\xf5es poss\xedveis); threads s\xe3o mais pesadas. Async/await \xe9 adequado para trabalho I/O-bound; threads s\xe3o adequadas para paralelismo CPU-bound. Escolha Go para concorr\xeancia simples; escolha async/await para servidores pesados em I/O; escolha threads quando precisar de paralelismo real e controle."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Comunica\xe7\xe3o baseada em channels \xe9 nativa em Go"})," -- Os channels embutidos do Go e o ",(0,r.jsx)(e.code,{children:"select"})," tornam padr\xf5es produtor-consumidor idiom\xe1ticos: ",(0,r.jsx)(e.code,{children:"ch := make(chan string)"}),", ",(0,r.jsx)(e.code,{children:'ch <- "msg"'}),", ",(0,r.jsx)(e.code,{children:"msg := <-ch"})," e ",(0,r.jsx)(e.code,{children:"select { case msg := <-ch1: ... case msg := <-ch2: ... }"}),". Rust oferece ",(0,r.jsx)(e.code,{children:"std::sync::mpsc::channel()"})," e C# tem ",(0,r.jsx)(e.code,{children:"Channel.CreateUnbounded<T>()"}),', mas s\xe3o recursos de biblioteca. O design do Go encoraja "compartilhar mem\xf3ria comunicando" em vez de usar mutexes. Se voc\xea constr\xf3i pipelines, pools de workers ou sistemas orientados a eventos, os channels do Go s\xe3o os mais ergon\xf4micos; Rust e C# fornecem poder similar com mais configura\xe7\xe3o.']}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Go e Rust se destacam em concorr\xeancia"})," -- As goroutines do Go s\xe3o leves (pilhas de 2KB, multiplexadas em threads do SO) e f\xe1ceis de criar: ",(0,r.jsx)(e.code,{children:"go worker(id)"}),". O modelo de ownership do Rust previne data races em tempo de compila\xe7\xe3o: o compilador rejeita compartilhamento de estado mut\xe1vel entre threads sem sincroniza\xe7\xe3o. Por exemplo, ",(0,r.jsx)(e.code,{children:"Arc<Mutex<i32>>"})," em Rust garante acesso compartilhado seguro. Go depende de channels e disciplina; Rust garante seguran\xe7a estaticamente. Escolha Go quando quiser concorr\xeancia simples e r\xe1pida com fric\xe7\xe3o m\xednima; escolha Rust quando precisar de m\xe1xima seguran\xe7a e performance sem coletor de lixo."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Swift introduz atores"})," -- Atores fornecem estado compartilhado thread-safe embutido ao serializar o acesso: ",(0,r.jsx)(e.code,{children:"actor Counter { private var count = 0; func increment() { count += 1 } }"})," -- todos os m\xe9todos executam serialmente, ent\xe3o n\xe3o h\xe1 data races. Voc\xea chama com ",(0,r.jsx)(e.code,{children:"await account.deposit(100)"}),". Isso substitui padr\xf5es manuais de ",(0,r.jsx)(e.code,{children:"Mutex"}),"/",(0,r.jsx)(e.code,{children:"Lock"}),". Os atores do Swift se integram com async/await e concorr\xeancia estruturada. Se voc\xea constr\xf3i sistemas concorrentes em Swift (ex.: iOS/macOS), prefira atores em vez de locking manual; para outras linguagens, use mutexes ou designs baseados em channels."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"JavaScript \xe9 single-threaded"})," -- O event loop lida com async via callbacks e Promises: ",(0,r.jsx)(e.code,{children:"await fetch('/api')"})," n\xe3o bloqueia a thread; ela cede at\xe9 a resposta chegar. Paralelismo real requer Web Workers (navegador) ou Worker Threads (Node.js) com ",(0,r.jsx)(e.code,{children:"postMessage"})," para comunica\xe7\xe3o. Trabalho pesado de CPU (hashing, processamento de imagem) bloqueia a thread principal; delegue-o para workers. Para servidores Node.js I/O-bound, async/await \xe9 suficiente; para tarefas CPU-bound, adicione workers ou considere uma linguagem multi-threaded como Go ou Rust."]}),"\n"]}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(u,{...n})}):u(n)}}}]);